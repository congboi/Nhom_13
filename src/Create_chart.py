# -*- coding: utf-8 -*-
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
import time
import warnings
from apriori_library import BasketPreparer, AssociationRulesMiner, FPGrowthMiner, WeightedAssociationMiner
from mlxtend.frequent_patterns import fpgrowth, association_rules

warnings.filterwarnings('ignore')

def solve_topic_2(input_csv, save_dir="reports/topic_2"):
    """
    H√†m ch√≠nh th·ª±c hi·ªán ch·ªß ƒë·ªÅ 2: So s√°nh Apriori vs FP-Growth v√† ph√¢n t√≠ch lu·∫≠t c√≥ tr·ªçng s·ªë.
    """
    print("üöÄ ƒêang kh·ªüi ƒë·ªông ph√¢n t√≠ch Ch·ªß ƒë·ªÅ 2...")
    print("=" * 60)
    
    # ====================== 1. CHU·∫®N B·ªä D·ªÆ LI·ªÜU ======================
    print("üìÇ 1. ƒêang t·∫£i v√† chu·∫©n b·ªã d·ªØ li·ªáu...")
    try:
        df_raw = pd.read_csv(input_csv, low_memory=False)
    except FileNotFoundError:
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y file: {input_csv}")
        print("‚ö†Ô∏è  Vui l√≤ng ki·ªÉm tra ƒë∆∞·ªùng d·∫´n file.")
        return
    
    # T·∫°o basket matrix
    print("   ‚Ä¢ ƒêang t·∫°o basket matrix...")
    bp = BasketPreparer(df_raw)
    basket_bool = bp.encode_basket(threshold=1)
    
    # T√≠nh tr·ªçng s·ªë (Monetary) cho m·ªói h√≥a ƒë∆°n
    df_raw['TotalValue'] = df_raw['Quantity'] * df_raw['UnitPrice']
    invoice_weights = df_raw.groupby('InvoiceNo')['TotalValue'].sum()
    total_revenue = invoice_weights.sum()
    
    print(f"   ‚Ä¢ K√≠ch th∆∞·ªõc basket: {basket_bool.shape}")
    print(f"   ‚Ä¢ T·ªïng s·ªë h√≥a ƒë∆°n: {len(basket_bool)}")
    print(f"   ‚Ä¢ T·ªïng s·ªë s·∫£n ph·∫©m: {len(basket_bool.columns)}")
    print(f"   ‚Ä¢ T·ªïng doanh thu: ¬£{total_revenue:,.2f}")
    
    # ====================== 2. PH√ÇN T√çCH HUB S·∫¢N PH·∫®M (QUAN TR·ªåNG) ======================
    print("\nüìä 2. ƒêang ph√¢n t√≠ch Hub s·∫£n ph·∫©m theo t·∫ßn su·∫•t v√† gi√° tr·ªã...")
    
    # T√≠nh weights vector
    weights_v = basket_bool.index.map(invoice_weights).fillna(0).values
    
    # Ph√¢n t√≠ch t·ª´ng s·∫£n ph·∫©m
    hub_list = []
    for prod in basket_bool.columns:
        mask = basket_bool[prod].values == 1
        freq = mask.mean()  # T·∫ßn su·∫•t (Support th∆∞·ªùng)
        if mask.any():
            val = weights_v[mask].sum() / total_revenue  # Weighted support
        else:
            val = 0.0
        
        hub_list.append({
            'Product': prod, 
            'Frequency': freq, 
            'Value': val
        })
    
    df_hub = pd.DataFrame(hub_list)
    
    # ====================== 3. TR·ª∞C QUAN H√ìA HUB S·∫¢N PH·∫®M ======================
    print("\nüé® 3. ƒêang t·∫°o bi·ªÉu ƒë·ªì Hub s·∫£n ph·∫©m...")
    
    # T·∫°o th∆∞ m·ª•c l∆∞u k·∫øt qu·∫£
    os.makedirs(save_dir, exist_ok=True)
    
    # Thi·∫øt l·∫≠p style cho bi·ªÉu ƒë·ªì
    plt.style.use('seaborn-v0_8')
    sns.set_palette("viridis")
    
    # ---- BI·ªÇU ƒê·ªí HUB S·∫¢N PH·∫®M ----
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8))
    
    # Top 10 Hub theo t·∫ßn su·∫•t
    top_f = df_hub.sort_values('Frequency', ascending=False).head(10)
    if not top_f.empty:
        # T·∫°o barplot v·ªõi palette 'viridis'
        bars1 = sns.barplot(data=top_f, x='Frequency', y='Product', ax=ax1, palette='viridis')
        ax1.set_title('TOP 10 HUB THEO T·∫¶N SU·∫§T\n(S·∫£n ph·∫©m xu·∫•t hi·ªán nhi·ªÅu nh·∫•t)', fontsize=14, fontweight='bold')
        ax1.set_xlabel('Frequency (Support)', fontsize=12)
        ax1.set_ylabel('S·∫£n ph·∫©m', fontsize=12)
        
        # ƒêi·ªÅu ch·ªânh font size cho t√™n s·∫£n ph·∫©m
        ax1.tick_params(axis='y', labelsize=10)
        
        # Th√™m gi√° tr·ªã tr√™n c√°c c·ªôt
        for i, (freq, product) in enumerate(zip(top_f['Frequency'], top_f['Product'])):
            ax1.text(freq + 0.001, i, f'{freq:.3f}', va='center', fontsize=10, fontweight='bold')
    
    # Top 10 Hub theo gi√° tr·ªã
    top_v = df_hub.sort_values('Value', ascending=False).head(10)
    if not top_v.empty:
        # T·∫°o barplot v·ªõi palette 'magma'
        bars2 = sns.barplot(data=top_v, x='Value', y='Product', ax=ax2, palette='magma')
        ax2.set_title('TOP 10 HUB THEO GI√Å TR·ªä\n(S·∫£n ph·∫©m ƒë√≥ng g√≥p doanh thu l·ªõn nh·∫•t)', fontsize=14, fontweight='bold')
        ax2.set_xlabel('Value (Weighted Support)', fontsize=12)
        ax2.set_ylabel('S·∫£n ph·∫©m', fontsize=12)
        
        # ƒêi·ªÅu ch·ªânh font size cho t√™n s·∫£n ph·∫©m
        ax2.tick_params(axis='y', labelsize=10)
        
        # Th√™m gi√° tr·ªã tr√™n c√°c c·ªôt
        for i, (val, product) in enumerate(zip(top_v['Value'], top_v['Product'])):
            ax2.text(val + 0.00001, i, f'{val:.5f}', va='center', fontsize=10, fontweight='bold')
    
    # ƒêi·ªÅu ch·ªânh layout
    plt.tight_layout()
    
    # L∆∞u bi·ªÉu ƒë·ªì
    plt.savefig(f"{save_dir}/hub_comparison_report.png", dpi=300, bbox_inches='tight')
    print(f"‚úÖ ƒê√£ l∆∞u bi·ªÉu ƒë·ªì Hub t·∫°i: {save_dir}/hub_comparison_report.png")
    
    # Hi·ªÉn th·ªã bi·ªÉu ƒë·ªì
    plt.show()
    
    # ====================== 4. TH·ª¨ NGHI·ªÜM SO S√ÅNH THU·∫¨T TO√ÅN (ƒê∆†N GI·∫¢N) ======================
    print("\nüî¨ 4. ƒêang th·ª±c nghi·ªám so s√°nh Apriori vs FP-Growth...")
    
    # Ch·ªâ ch·∫°y v·ªõi 2 gi√° tr·ªã min_support ƒë·ªÉ tr√°nh l·ªói
    support_values = [0.05, 0.03]
    min_confidence = 0.3
    
    experiment_results = []
    
    for min_sup in support_values:
        print(f"   ‚Ä¢ ƒêang ch·∫°y v·ªõi min_support = {min_sup:.3f}...")
        
        # FP-Growth
        try:
            fp_start = time.time()
            fp_miner = FPGrowthMiner(basket_bool)
            freq_items_fp = fp_miner.run(min_support=min_sup, use_colnames=True)
            
            if len(freq_items_fp) > 0:
                rules_fp = association_rules(freq_items_fp, metric="confidence", 
                                            min_threshold=min_confidence)
                rules_fp = rules_fp[rules_fp['lift'] >= 1.0]
            else:
                rules_fp = pd.DataFrame()
            
            fp_time = time.time() - fp_start
            
        except Exception as e:
            print(f"     - FP-Growth l·ªói: {str(e)[:50]}...")
            fp_time = 0
            rules_fp = pd.DataFrame()
        
        # Apriori (ch·ªâ ch·∫°y v·ªõi min_sup >= 0.03)
        if min_sup >= 0.03:
            try:
                ap_start = time.time()
                ap_miner = AssociationRulesMiner(basket_bool)
                freq_items_ap = ap_miner.mine_frequent_itemsets(min_support=min_sup, 
                                                              use_colnames=True)
                
                if len(freq_items_ap) > 0:
                    rules_ap = ap_miner.generate_rules(metric="confidence", 
                                                      min_threshold=min_confidence)
                    rules_ap = rules_ap[rules_ap['lift'] >= 1.0]
                else:
                    rules_ap = pd.DataFrame()
                
                ap_time = time.time() - ap_start
                
            except Exception as e:
                print(f"     - Apriori l·ªói: {str(e)[:50]}...")
                ap_time = 0
                rules_ap = pd.DataFrame()
        else:
            ap_time = 0
            rules_ap = pd.DataFrame()
        
        experiment_results.append({
            'min_support': min_sup,
            'FP_Time': fp_time,
            'AP_Time': ap_time,
            'FP_Rules': len(rules_fp),
            'AP_Rules': len(rules_ap),
        })
    
    df_results = pd.DataFrame(experiment_results)
    
    # ====================== 5. T√çNH TO√ÅN LU·∫¨T C√ì TR·ªåNG S·ªê ======================
    print("\n‚öñÔ∏è 5. ƒêang t√≠nh to√°n lu·∫≠t k·∫øt h·ª£p c√≥ tr·ªçng s·ªë...")
    
    # Ch·ªçn min_support = 0.03 ƒë·ªÉ ƒë·∫£m b·∫£o c√≥ k·∫øt qu·∫£
    target_min_support = 0.03
    
    try:
        fp_miner = FPGrowthMiner(basket_bool)
        freq_items = fp_miner.run(min_support=target_min_support, use_colnames=True)
        
        if len(freq_items) > 0:
            rules = association_rules(freq_items, metric="confidence", 
                                     min_threshold=min_confidence)
            rules = rules[rules['lift'] >= 1.0]
            
            # T√≠nh to√°n c√°c metrics c√≥ tr·ªçng s·ªë
            w_miner = WeightedAssociationMiner()
            rules_weighted = w_miner.compute_weighted_metrics(rules.copy(), 
                                                             basket_bool, df_raw)
            
            # Th√™m c·ªôt ƒë·ªçc ƒë∆∞·ª£c
            rules_weighted['antecedents_str'] = rules_weighted['antecedents'].apply(
                lambda x: ', '.join(sorted(list(x)))
            )
            rules_weighted['consequents_str'] = rules_weighted['consequents'].apply(
                lambda x: ', '.join(sorted(list(x)))
            )
            rules_weighted['rule_str'] = rules_weighted['antecedents_str'] + ' ‚Üí ' + rules_weighted['consequents_str']
            
            print(f"   ‚Ä¢ S·ªë lu·∫≠t c√≥ tr·ªçng s·ªë: {len(rules_weighted)}")
            
            # L∆∞u k·∫øt qu·∫£
            rules_weighted.to_csv(f"{save_dir}/weighted_association_rules.csv", index=False)
        else:
            rules_weighted = pd.DataFrame()
            print(f"   ‚Ä¢ Kh√¥ng t√¨m th·∫•y lu·∫≠t n√†o v·ªõi min_support = {target_min_support}")
            
    except Exception as e:
        print(f"   ‚Ä¢ L·ªói khi t√≠nh to√°n lu·∫≠t c√≥ tr·ªçng s·ªë: {str(e)[:100]}...")
        rules_weighted = pd.DataFrame()
    
    # ====================== 6. T·∫†O BI·ªÇU ƒê·ªí SO S√ÅNH ======================
    print("\nüìà 6. ƒêang t·∫°o bi·ªÉu ƒë·ªì so s√°nh thu·∫≠t to√°n...")
    
    if len(df_results) > 0 and df_results['FP_Time'].sum() > 0:
        fig2, axes2 = plt.subplots(1, 2, figsize=(15, 6))
        
        # Bi·ªÉu ƒë·ªì th·ªùi gian ch·∫°y
        valid_data = df_results[df_results['FP_Time'] > 0]
        
        if len(valid_data) > 0:
            axes2[0].plot(valid_data['min_support'], valid_data['FP_Time'], 
                         marker='o', markersize=8, linewidth=2.5, label='FP-Growth')
            axes2[0].plot(valid_data['min_support'], valid_data['AP_Time'], 
                         marker='s', markersize=8, linewidth=2.5, label='Apriori')
            axes2[0].set_xlabel('Min Support Threshold', fontsize=12)
            axes2[0].set_ylabel('Th·ªùi gian ch·∫°y (gi√¢y)', fontsize=12)
            axes2[0].set_title('SO S√ÅNH TH·ªúI GIAN CH·∫†Y\nFP-Growth vs Apriori', 
                             fontsize=14, fontweight='bold')
            axes2[0].legend(fontsize=11)
            axes2[0].grid(True, linestyle='--', alpha=0.7)
            axes2[0].invert_xaxis()
        
        # Bi·ªÉu ƒë·ªì s·ªë l∆∞·ª£ng lu·∫≠t
        axes2[1].plot(valid_data['min_support'], valid_data['FP_Rules'], 
                     marker='o', markersize=8, linewidth=2.5, label='FP-Growth')
        axes2[1].plot(valid_data['min_support'], valid_data['AP_Rules'], 
                     marker='s', markersize=8, linewidth=2.5, label='Apriori')
        axes2[1].set_xlabel('Min Support Threshold', fontsize=12)
        axes2[1].set_ylabel('S·ªë l∆∞·ª£ng lu·∫≠t sinh ra', fontsize=12)
        axes2[1].set_title('SO S√ÅNH S·ªê L∆Ø·ª¢NG LU·∫¨T\nFP-Growth vs Apriori', 
                         fontsize=14, fontweight='bold')
        axes2[1].legend(fontsize=11)
        axes2[1].grid(True, linestyle='--', alpha=0.7)
        axes2[1].invert_xaxis()
        
        plt.tight_layout()
        plt.savefig(f"{save_dir}/algorithm_comparison.png", dpi=300, bbox_inches='tight')
        print(f"‚úÖ ƒê√£ l∆∞u bi·ªÉu ƒë·ªì so s√°nh thu·∫≠t to√°n")
    
    # ====================== 7. L∆ØU K·∫æT QU·∫¢ V√Ä B√ÅO C√ÅO ======================
    print("\nüíæ 7. ƒêang l∆∞u k·∫øt qu·∫£ ph√¢n t√≠ch...")
    
    # L∆∞u k·∫øt qu·∫£ th·ª≠ nghi·ªám
    df_results.to_csv(f"{save_dir}/experiment_results.csv", index=False)
    
    # L∆∞u k·∫øt qu·∫£ hub s·∫£n ph·∫©m
    df_hub.to_csv(f"{save_dir}/product_hub_analysis.csv", index=False)
    
    # T·∫°o b√°o c√°o
    print("\n" + "="*60)
    print("üìã B√ÅO C√ÅO K·∫æT QU·∫¢")
    print("="*60)
    
    # Hi·ªÉn th·ªã top s·∫£n ph·∫©m
    print("\nTOP 5 S·∫¢N PH·∫®M THEO T·∫¶N SU·∫§T:")
    print("-" * 40)
    for i, (_, row) in enumerate(df_hub.nlargest(5, 'Frequency').iterrows(), 1):
        print(f"{i}. {row['Product'][:50]}... - Frequency: {row['Frequency']:.4f}")
    
    print("\nTOP 5 S·∫¢N PH·∫®M THEO GI√Å TR·ªä:")
    print("-" * 40)
    for i, (_, row) in enumerate(df_hub.nlargest(5, 'Value').iterrows(), 1):
        print(f"{i}. {row['Product'][:50]}... - Value: {row['Value']:.6f}")
    
    print(f"\n‚úÖ HO√ÄN TH√ÄNH PH√ÇN T√çCH!")
    print(f"üìÅ T·∫•t c·∫£ k·∫øt qu·∫£ ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: {save_dir}")
    print("="*60)

if __name__ == "__main__":
    # ƒê∆∞·ªùng d·∫´n ƒë·∫øn d·ªØ li·ªáu ƒë√£ l√†m s·∫°ch
    PATH = "data/processed/cleaned_uk_data.csv"
    
    # Ch·∫°y ph√¢n t√≠ch
    solve_topic_2(PATH, save_dir="reports/topic_2")